{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41761b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ac325202235b>:46: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Tune Talk Yearly 200 Details Collected!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "now = datetime.now()\n",
    "date = now.date()\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "extraxtion_date = now.date()\n",
    "date = extraxtion_date.strftime(\"%Y%m%d\")\n",
    "path = 'C:/Users/JenarthananRajenthir/OneDrive - ADA Asia/Documents/Final_telco/Data/MY/Tune_Talk/'+  date + '/'   \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "urls = ['https://www.tunetalk.com/my/en/coolplan/hi-value-prepaid']\n",
    "\n",
    "df = pd.DataFrame(columns=['Package_name', 'Package_price', 'Extraxtion_Date', 'Validity_Period', 'Validity_Period_Unit', 'High-Speed_data', 'Unlimited_Calls', 'HotSpot', 'Data_for_Apps', 'Apps', 'Booster_Data'])\n",
    "                   \n",
    "for url in urls:\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--allow-running-insecure-content')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--proxy-server='direct://'\")\n",
    "    options.add_argument(\"--proxy-bypass-list=*\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n",
    "    browser.get(url)\n",
    "    html_source_code = browser.execute_script(\"return document.innerHTML;\")\n",
    "    browser.set_page_load_timeout(10)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    browser.implicitly_wait(10)\n",
    "    \n",
    "    plans = list(soup.find_all('div', attrs = {'id':'plan-area'})[0].find_all('div', attrs = {'owl-item'})) \n",
    "      \n",
    "    for i in range(len(plans)): \n",
    "        package_name = soup.find_all('div', attrs = {'class':'Header'})[i].find('h4', attrs = {'class':'text-xlg'}).text\n",
    "        package_price = soup.find_all('div', attrs = {'class':'Header'})[i].find('p', attrs = {'class':'mt-5 text-bold'}).find('span').text\n",
    "        validity_period = soup.find_all('div', attrs = {'class':'Header'})[i].find_all('p', attrs = {'class':'mt-5 text-xs'})[0].text.split(' ')[2]\n",
    "        validity_period_unit = soup.find_all('div', attrs = {'class':'Header'})[i].find_all('p', attrs = {'class':'mt-5 text-xs'})[0].text.split(' ')[3]\n",
    "        hi_speed_data = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'mb-20'})[0].find('div', attrs = {'class':'inline benefit-copy text-sm'}).text\n",
    "        unlimited_calls = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'mb-20'})[1].find('div', attrs = {'class':'inline benefit-copy text-sm'}).text\n",
    "        hotspot = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'inline benefit-copy text-sm'})[2].text\n",
    "        \n",
    "        if i==3:\n",
    "            data_for_apps_list = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'inline benefit-copy text-sm'})[3].text.split(' ')[:2]\n",
    "            data_for_apps = data_for_apps_list[0].strip() + ' ' + data_for_apps_list[1].strip()\n",
    "            app_1 = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'inline benefit-copy text-sm'})[3].find_all('img', attrs = {'class':'fr-dib fr-draggable img-inline'})[0].get('title')\n",
    "            app_2 = soup.find_all('div', attrs = {'class':'content1'})[i].find_all('div', attrs = {'class':'inline benefit-copy text-sm'})[3].find_all('img', attrs = {'class':'fr-dib fr-draggable img-inline'})[1].get('title')\n",
    "            apps = app_1+', '+app_2\n",
    "        else:\n",
    "            data_for_apps = ''\n",
    "            apps = ''\n",
    "        \n",
    "        booster_list = list(soup.find_all('div', attrs = {'class':'content2 text-sm'})[i].find_all('p', attrs = {'class':'text-bold'}))\n",
    "        booster_data = ''\n",
    "        for j in range(len(booster_list)):\n",
    "            booster_data += soup.find_all('div', attrs = {'class':'content2 text-sm'})[i].find_all('p', attrs = {'class':'text-bold'})[j].text+ ', '\n",
    "        \n",
    "        df = df.append({'Package_name': package_name, 'Package_price': package_price, 'Extraxtion_Date': extraxtion_date, 'Validity_Period': validity_period, 'Validity_Period_Unit': validity_period_unit, 'High-Speed_data': hi_speed_data, 'Unlimited_Calls':unlimited_calls, 'HotSpot':hotspot, 'Data_for_Apps': data_for_apps, 'Apps': apps, 'Booster_Data':booster_data}, ignore_index=True)\n",
    "\n",
    "    df.to_csv(path+date+'hi-value_packages.csv', index=False)\n",
    "    print('Successfully Tune Talk '+package_name+' Details Collected!')\n",
    "    \n",
    "    \n",
    "    browser.quit()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9b9350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f53a49c1c4c6>:46: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Tune Talk Unlimited Calls Details Collected!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "now = datetime.now()\n",
    "date = now.date()\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "extraxtion_date = now.date()\n",
    "date = extraxtion_date.strftime(\"%Y%m%d\")\n",
    "path = 'C:/Users/JenarthananRajenthir/OneDrive - ADA Asia/Documents/Final_telco/Data/MY/Tune_Talk/'+  date + '/'               \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "urls = ['https://www.tunetalk.com/my/en/coolplan/hi-value-prepaid']\n",
    "\n",
    "df = pd.DataFrame(columns=['AddOn_name', 'AddOn_price', 'Extraxtion_Date', 'Validity_Period', 'AddOn_benifits', 'Applicable_Plans'])\n",
    "                   \n",
    "for url in urls:\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--allow-running-insecure-content')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--proxy-server='direct://'\")\n",
    "    options.add_argument(\"--proxy-bypass-list=*\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n",
    "    browser.get(url)\n",
    "    html_source_code = browser.execute_script(\"return document.innerHTML;\")\n",
    "    browser.set_page_load_timeout(10)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    browser.implicitly_wait(10)\n",
    "    \n",
    "    plans = list(soup.find_all('div', attrs = {'id':'addon'})[0].find_all('div', attrs = {'owl-item'})) \n",
    "      \n",
    "    for i in range(len(plans)): \n",
    "        addon_name = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'Header'}).find('h4', attrs = {'class':'text-lg white-color'}).text\n",
    "        addon_price = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'Header'}).find('p', attrs = {'class':'mt-5 text-bold'}).find('span').text\n",
    "        validity_period = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'content1'}).find('div', attrs = {'class':'benefit-copy text-sm'}).text\n",
    "        benifits = list(soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'content1'}).find_all('div', attrs = {'class':'mt-10 benefit-copy text-sm'}))\n",
    "        if len(benifits)>1:\n",
    "            addon_benifits = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'content1'}).find_all('div', attrs = {'class':'mt-10 benefit-copy text-sm'})[0].text\n",
    "            applicable_plans = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'content1'}).find_all('div', attrs = {'class':'mt-10 benefit-copy text-sm'})[1].text\n",
    "        elif len(benifits)==1:\n",
    "            addon_benifits = ''\n",
    "            applicable_plans = soup.find_all('div', attrs = {'class':'addon-list'})[i].find('div', attrs = {'class':'content1'}).find_all('div', attrs = {'class':'mt-10 benefit-copy text-sm'})[0].text\n",
    "        else:\n",
    "            addon_benifits = ''\n",
    "            applicable_plans = ''\n",
    "        \n",
    "        df = df.append({'AddOn_name': addon_name, 'AddOn_price': addon_price, 'Extraxtion_Date': extraxtion_date, 'Validity_Period': validity_period, 'AddOn_benifits': addon_benifits, 'Applicable_Plans':applicable_plans}, ignore_index=True)\n",
    "\n",
    "    df.to_csv(path+date+'hi-value_addons.csv', index=False)\n",
    "    print('Successfully Tune Talk '+addon_name+' Details Collected!')\n",
    "    \n",
    "    \n",
    "    browser.quit()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82463f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-77fde0a00deb>:45: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dailyweekly\n",
      "2\n",
      "Successfully Tune Talk  Details Collected!\n",
      "monthlyyearly\n",
      "4\n",
      "\n",
      "ADD-ONS AVAILABLE\n",
      "6GB Hi-Speed Video\n",
      "10GB BOOSTER ADD-ONS AVAILABLE\n",
      "40GB Hi-Speed Video\n",
      "10GB BOOSTER ADD-ONS AVAILABLE\n",
      "Successfully Tune Talk  Details Collected!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "now = datetime.now()\n",
    "date = now.date()\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "extraxtion_date = now.date()\n",
    "date = extraxtion_date.strftime(\"%Y%m%d\")\n",
    "path = 'C:/Users/JenarthananRajenthir/OneDrive - ADA Asia/Documents/Final_telco/Data/MY/Tune_Talk/'+  date + '/'                 \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "urls = ['https://www.tunetalk.com/my/en/coolplan/data/sureone#dailyweekly', 'https://www.tunetalk.com/my/en/coolplan/data/sureone#monthlyyearly']\n",
    "df_final = pd.DataFrame(columns=['Plan_Type', 'Plan_Price', 'Extraxtion_Date', 'Price_Period', 'High-speed_Data', 'Unlimited_Calls', 'Call_Network', 'Basic_Internet', 'Video_Data', 'Booster_Data', 'Chat_Call_Social'])    \n",
    "       \n",
    "for url in urls:\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--allow-running-insecure-content')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--proxy-server='direct://'\")\n",
    "    options.add_argument(\"--proxy-bypass-list=*\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n",
    "    browser.get(url)\n",
    "    html_source_code = browser.execute_script(\"return document.innerHTML;\")\n",
    "    browser.set_page_load_timeout(10)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    browser.implicitly_wait(10)\n",
    "    url_split = url.split('#')\n",
    "    plan_duration = url_split[1]\n",
    "    \n",
    "       \n",
    "    duration = {'dailyweekly':'daily-weekly', 'monthlyyearly': 'monthly-yearly'}                \n",
    "    print(plan_duration)\n",
    "    plans = list(soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'owl-item'})) \n",
    "    print(len(plans))\n",
    "    for i in range(len(plans)): \n",
    "        plan_type = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'owl-item'})[i].find_all('div', attrs = {'class':'text-lg text-bold'})[0].text\n",
    "        price = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'owl-item'})[i].find_all('div', attrs = {'class':'text-lg text-bold'})[1].text\n",
    "        plan_price = price.split('/')[0].strip()\n",
    "        price_period = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'owl-item'})[i].find_all('div', attrs = {'class':'text-lg text-bold'})[1].find('span').text.split('/')[1]\n",
    "        hi_speed_data = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find_all('div', attrs = {'class':'text-md'})[0].find_all('strong')[0].text\n",
    "        unlimited_calls = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find_all('div', attrs = {'class':'text-md mt-10'})[0].find_all('strong')[0].text\n",
    "        call_network = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find_all('div', attrs = {'class':'text-xs'})[1].text\n",
    "        basic_internet = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find_all('div', attrs = {'class':'text-md mt-10'})[1].find_all('strong')[0].text\n",
    "        if (plan_duration == 'monthlyyearly') & (i < len(plans)-1):\n",
    "            if (i == 1) or (i==2):\n",
    "                video_data = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find('div', attrs = {'class':'text-lg red-color mt-10'}).find('strong').text\n",
    "            print(video_data)\n",
    "            booster_data = soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find('div', attrs = {'class':'sureone-addon'}).find('div', attrs = {'class':'text-md red-color'}).text\n",
    "            print(booster_data)\n",
    "            unlimited_options = list(soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find('div', attrs = {'class':'sureone-addon'}).find('div', attrs = {'class':'passes red-color'}).find_all('div', attrs = {'class':'passes-area pass-adj'}))\n",
    "            chat_call_social = []\n",
    "            for j in range(len(unlimited_options)):\n",
    "                chat_call_social.append(soup.find('div', attrs = {'id':duration[plan_duration]}).find_all('div', attrs = {'class':'lower lower-box lower-box-overview'})[i].find_all('div', attrs = {'class':'sureone-addon'})[0].find_all('div', attrs = {'class':'passes red-color'})[0].find_all('div', attrs = {'class':'passes-area pass-adj'})[j].find_all('div', attrs = {'class':'text-md'})[0].text)\n",
    "        else:\n",
    "            video_data = '' \n",
    "            booster_data = ''\n",
    "            chat_call_social = ''\n",
    "            \n",
    "        df_final = df_final.append({'Plan_Type':plan_type, 'Plan_Price':plan_price,'Extraxtion_Date': extraxtion_date,'Price_Period':price_period, 'High-speed_Data':hi_speed_data, 'Unlimited_Calls':unlimited_calls, 'Call_Network':call_network, 'Basic_Internet':basic_internet, 'Video_Data':video_data, 'Booster_Data':booster_data, 'Chat_Call_Social':chat_call_social}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    df_final.to_csv(path+date+'_'+'sureone_packages.csv', index=False)\n",
    "    print('Successfully Tune Talk '+' Details Collected!')\n",
    "    \n",
    "    browser.quit()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69be18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d6fa00f3a252>:48: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Tune Talk Y1s  Details Collected!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "now = datetime.now()\n",
    "date = now.date()\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "extraxtion_date = now.date()\n",
    "date = extraxtion_date.strftime(\"%Y%m%d\")\n",
    "path = 'C:/Users/JenarthananRajenthir/OneDrive - ADA Asia/Documents/Final_telco/Data/MY/Tune_Talk/'+  date + '/'   \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "urls = ['https://www.tunetalk.com/my/en/store/product/VivoY1s', 'https://www.tunetalk.com/my/en/store/product/VivoY33s', 'https://www.tunetalk.com/my/en/store/product/VivoX70Pro',\n",
    "        'https://www.tunetalk.com/my/en/store/product/VivoY15s', 'https://www.tunetalk.com/my/en/store/product/VivoY76-5G'\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(columns=['Device_Brand', 'Device_Name', 'Extraxtion_Date', 'Storage_Size', 'Device_Price', 'Big_points', 'Total_amount', 'Availability'])\n",
    "    \n",
    "for url in urls:\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--allow-running-insecure-content')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--proxy-server='direct://'\")\n",
    "    options.add_argument(\"--proxy-bypass-list=*\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    browser = webdriver.Chrome(executable_path='../../chromedriver.exe', options=options)\n",
    "    browser.get(url)\n",
    "    html_source_code = browser.execute_script(\"return document.innerHTML;\")\n",
    "    browser.set_page_load_timeout(10)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    browser.implicitly_wait(10)\n",
    "    \n",
    "    try:\n",
    "        df_final = pd.DataFrame(columns=['Device_Brand', 'Device_Name', 'Extraxtion_Date', 'Storage_Size', 'Device_Price', 'Big_points', 'Total_amount', 'Availability'])\n",
    "\n",
    "        device = soup.find_all('div', attrs = {'class':'section pt-40 pb-40 white-bg'})[0].find_all('div', attrs = {'class':'text-xlg mt-20 mb-20'})[0].text\n",
    "        devices = device.split(' ')\n",
    "        device_brand = devices[0].strip()\n",
    "\n",
    "        device_name = devices[1].strip()\n",
    "        if len(devices) > 2:\n",
    "            for i in range(2,len(devices)):\n",
    "                name = ' ' + devices[i].strip()\n",
    "                device_name += name\n",
    "        \n",
    "        storage = soup.find_all('div', attrs = {'class':'section pt-50'})[0].find_all('div', attrs = {'id':'tab-specifications'})[0].find_all('p')[-7].text[:-1]\n",
    "        device_price = soup.find_all('div', attrs = {'class':'product-detail-result-box'})[0].find_all('div', attrs = {'class':'col-xs-5 product-detail-result-box-amount'})[0].text\n",
    "        big_points = soup.find_all('div', attrs = {'class':'product-detail-result-box'})[0].find_all('div', attrs = {'class':'col-xs-5 product-detail-result-box-amount'})[1].text\n",
    "        total_amount = soup.find_all('div', attrs = {'class':'product-detail-result-box'})[0].find_all('div', attrs = {'class':'col-xs-8 product-detail-result-box-amount'})[0].text\n",
    "        availability = soup.find_all('div', attrs = {'class':'product-detail-result-box'})[0].find_all('a', attrs = {'id':'add-to-cart-btn'})[0].text\n",
    "\n",
    "        df_final = df_final.append({'Device_Brand': device_brand, 'Device_Name': device_name, 'Extraxtion_Date': extraxtion_date, 'Storage_Size': storage, 'Device_Price': device_price, 'Big_points': big_points, 'Total_amount': total_amount,  'Availability': availability}, ignore_index=True)\n",
    "\n",
    "    #     df_final.to_csv(path+date+'_'+device_name+'_devices.csv', index=False)\n",
    "        print('Successfully Tune Talk '+device_name+' Details Collected!')\n",
    "\n",
    "#         df = df.append({'Device_Brand': device_brand, 'Device_Name': device_name, 'Extraxtion_Date': extraxtion_date, 'Storage_Size': storage, 'Device_Price': device_price, 'Big_points': big_points, 'Total_amount': total_amount,  'Availability': availability}, ignore_index=True)\n",
    "\n",
    "        browser.quit()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "\n",
    "df_final.to_csv(path+date+'_all_devices.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b2a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
